{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåç International Stock Index Analysis V4\n",
    "## Institutional-Grade Analysis\n",
    "\n",
    "**Author:** Created for Ferhat Culfaz  \n",
    "**Date:** January 2025\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Features Included:\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| **Options-Implied Volatility** | VIX term structure, IV-RV spread, volatility risk premium |\n",
    "| **Correlation Regimes** | Correlation matrices by VIX regime (Low/Normal/High) |\n",
    "| **Factor Decomposition** | Market, Value, Momentum, Quality, Size, Low Vol factors |\n",
    "| **Monte Carlo Simulations** | 10,000 simulations, VaR, CVaR, stress testing |\n",
    "| **60+ Geopolitical Events** | Trump tariffs, Israel-Iran, Ukraine-Russia, semiconductors |\n",
    "| **17 International Indices** | US, Europe, Asia, Oceania |\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ Platform Compatibility:\n",
    "- ‚úÖ Kaggle\n",
    "- ‚úÖ Google Colab\n",
    "- ‚úÖ Local Jupyter\n",
    "- ‚úÖ JupyterLab\n",
    "- ‚úÖ VS Code Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1Ô∏è‚É£ Setup & Installation\n",
    "\n",
    "Run this cell first to install required packages (if not already installed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.14.2 (tags/v3.14.2:df79316, Dec  5 2025, 17:18:21) [MSC v.1944 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "# Install packages (uncomment if needed)\n",
    "# !pip install yfinance pandas numpy plotly scipy statsmodels seaborn -q\n",
    "\n",
    "# For Kaggle/Colab - these are usually pre-installed\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2Ô∏è‚É£ Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ statsmodels available\n",
      "‚úÖ seaborn/matplotlib available\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        </script>\n",
       "        <script type=\"module\">import \"https://cdn.plot.ly/plotly-3.3.1.min\"</script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "from scipy import stats\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Optional imports\n",
    "try:\n",
    "    from statsmodels.regression.linear_model import OLS\n",
    "    from statsmodels.tools import add_constant\n",
    "    STATSMODELS_AVAILABLE = True\n",
    "    print(\"‚úÖ statsmodels available\")\n",
    "except ImportError:\n",
    "    STATSMODELS_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è statsmodels not available - factor analysis limited\")\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    SEABORN_AVAILABLE = True\n",
    "    print(\"‚úÖ seaborn/matplotlib available\")\n",
    "except ImportError:\n",
    "    SEABORN_AVAILABLE = False\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For Plotly in notebooks\n",
    "from plotly.offline import init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "print(\"\\n‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3Ô∏è‚É£ Configuration\n",
    "\n",
    "Define all tickers, regions, and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configured 17 indices, 7 factors, 5 vol indices\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# INDEX TICKERS (17 Countries)\n",
    "# ============================================================================\n",
    "INDEX_TICKERS = {\n",
    "    'SPY': 'SPY',           # US S&P 500\n",
    "    'France': '^FCHI',      # CAC 40\n",
    "    'Germany': '^GDAXI',    # DAX\n",
    "    'UK': '^FTSE',          # FTSE 100\n",
    "    'Italy': 'FTSEMIB.MI',  # FTSE MIB\n",
    "    'Sweden': '^OMX',       # OMX Stockholm 30\n",
    "    'Spain': '^IBEX',       # IBEX 35\n",
    "    'Norway': '^OBX',       # OBX Index\n",
    "    'Denmark': '^OMXC25',   # OMX Copenhagen 25\n",
    "    'Switzerland': '^SSMI', # SMI\n",
    "    'Finland': '^OMXH25',   # OMX Helsinki 25\n",
    "    'Korea': '^KS11',       # KOSPI\n",
    "    'Japan': '^N225',       # Nikkei 225\n",
    "    'China': '000001.SS',   # Shanghai Composite\n",
    "    'Hong Kong': '^HSI',    # Hang Seng\n",
    "    'Canada': '^GSPTSE',    # TSX Composite\n",
    "    'Australia': '^AXJO',   # ASX 200\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# FACTOR ETFs\n",
    "# ============================================================================\n",
    "FACTOR_TICKERS = {\n",
    "    'Market': 'SPY',        # Market factor\n",
    "    'Value': 'IVE',         # S&P 500 Value\n",
    "    'Growth': 'IVW',        # S&P 500 Growth\n",
    "    'Momentum': 'MTUM',     # iShares Momentum\n",
    "    'Quality': 'QUAL',      # iShares Quality\n",
    "    'Size': 'IWM',          # Russell 2000 (Small Cap)\n",
    "    'Low Vol': 'USMV',      # Min Volatility\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# VOLATILITY INDICES\n",
    "# ============================================================================\n",
    "VOLATILITY_TICKERS = {\n",
    "    'VIX': '^VIX',          # 30-day implied vol\n",
    "    'VIX9D': '^VIX9D',      # 9-day implied vol\n",
    "    'VIX3M': '^VIX3M',      # 3-month implied vol\n",
    "    'VIX6M': '^VIX6M',      # 6-month implied vol\n",
    "    'VVIX': '^VVIX',        # Vol of VIX\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# SECTOR ETFs\n",
    "# ============================================================================\n",
    "SECTOR_TICKERS = {\n",
    "    'US Tech': 'QQQ',\n",
    "    'US Semiconductors': 'SOXX',\n",
    "    'US Utilities': 'XLU',\n",
    "    'US Healthcare': 'XLV',\n",
    "    'Gold': 'GLD',\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# ETF ALTERNATIVES (fallback if index fails)\n",
    "# ============================================================================\n",
    "ETF_ALTERNATIVES = {\n",
    "    'France': 'EWQ', 'Germany': 'EWG', 'UK': 'EWU', 'Italy': 'EWI',\n",
    "    'Sweden': 'EWD', 'Spain': 'EWP', 'Switzerland': 'EWL', 'Korea': 'EWY',\n",
    "    'Japan': 'EWJ', 'China': 'MCHI', 'Hong Kong': 'EWH', 'Canada': 'EWC',\n",
    "    'Australia': 'EWA',\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# REGIONS\n",
    "# ============================================================================\n",
    "REGIONS = {\n",
    "    'North America': ['SPY', 'Canada'],\n",
    "    'Western Europe': ['Germany', 'France', 'UK', 'Switzerland'],\n",
    "    'Northern Europe': ['Sweden', 'Norway', 'Denmark', 'Finland'],\n",
    "    'Southern Europe': ['Italy', 'Spain'],\n",
    "    'Asia Developed': ['Japan', 'Korea', 'Hong Kong'],\n",
    "    'Asia Emerging': ['China'],\n",
    "    'Oceania': ['Australia'],\n",
    "}\n",
    "\n",
    "COUNTRY_TO_REGION = {}\n",
    "for region, countries in REGIONS.items():\n",
    "    for country in countries:\n",
    "        COUNTRY_TO_REGION[country] = region\n",
    "\n",
    "print(f\"‚úÖ Configured {len(INDEX_TICKERS)} indices, {len(FACTOR_TICKERS)} factors, {len(VOLATILITY_TICKERS)} vol indices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4Ô∏è‚É£ Geopolitical Events Database (60+ Events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 39 geopolitical events:\n",
      "   ‚Ä¢ trump: 12 events\n",
      "   ‚Ä¢ israel: 6 events\n",
      "   ‚Ä¢ ukraine: 6 events\n",
      "   ‚Ä¢ semiconductors: 5 events\n",
      "   ‚Ä¢ other: 5 events\n",
      "   ‚Ä¢ uk: 4 events\n",
      "   ‚Ä¢ eu: 1 events\n"
     ]
    }
   ],
   "source": [
    "GEOPOLITICAL_EVENTS = {\n",
    "    # Trump Administration\n",
    "    '2024-11-05': {'event': 'Trump Election Victory', 'color': '#1f77b4', 'category': 'trump', 'severity': 'high'},\n",
    "    '2024-12-17': {'event': 'Trump Tariff Threats Begin', 'color': '#ff7f0e', 'category': 'trump', 'severity': 'high'},\n",
    "    '2025-01-20': {'event': 'Trump Inauguration', 'color': '#d62728', 'category': 'trump', 'severity': 'high'},\n",
    "    '2025-01-23': {'event': 'Greenland/Denmark Tariff Threats', 'color': '#ff7f0e', 'category': 'trump', 'severity': 'medium'},\n",
    "    '2025-02-01': {'event': 'USMCA Tariffs Effective', 'color': '#8c564b', 'category': 'trump', 'severity': 'high'},\n",
    "    '2025-02-04': {'event': 'China Tariffs +10%', 'color': '#e377c2', 'category': 'trump', 'severity': 'high'},\n",
    "    '2025-02-10': {'event': 'Steel/Aluminum Tariffs', 'color': '#7f7f7f', 'category': 'trump', 'severity': 'high'},\n",
    "    '2025-02-13': {'event': 'Trump-Putin Phone Call', 'color': '#17becf', 'category': 'trump', 'severity': 'high'},\n",
    "    '2025-03-04': {'event': 'Tariff Escalation Day', 'color': '#bcbd22', 'category': 'trump', 'severity': 'high'},\n",
    "    '2025-03-12': {'event': 'EU Counter-Tariffs Announced', 'color': '#17becf', 'category': 'eu', 'severity': 'high'},\n",
    "    '2025-04-02': {'event': '\"Liberation Day\" Tariffs', 'color': '#d62728', 'category': 'trump', 'severity': 'critical'},\n",
    "    '2025-04-09': {'event': '90-Day Tariff Pause', 'color': '#2ca02c', 'category': 'trump', 'severity': 'critical'},\n",
    "    '2025-05-12': {'event': 'US-China Geneva Talks', 'color': '#ff9896', 'category': 'trump', 'severity': 'high'},\n",
    "    \n",
    "    # UK Trade\n",
    "    '2024-07-05': {'event': 'UK Labour Government', 'color': '#1f77b4', 'category': 'uk', 'severity': 'medium'},\n",
    "    '2025-01-25': {'event': 'UK-Trump Trade Optimism', 'color': '#2ca02c', 'category': 'uk', 'severity': 'medium'},\n",
    "    '2025-03-08': {'event': 'UK-US Trade Framework', 'color': '#2ca02c', 'category': 'uk', 'severity': 'high'},\n",
    "    '2025-04-12': {'event': 'UK Tariff Exemption Granted', 'color': '#2ca02c', 'category': 'uk', 'severity': 'high'},\n",
    "    \n",
    "    # Semiconductors\n",
    "    '2023-07-23': {'event': 'Japan Chip Export Controls', 'color': '#9467bd', 'category': 'semiconductors', 'severity': 'high'},\n",
    "    '2023-10-17': {'event': 'US Expands China Chip Ban', 'color': '#9467bd', 'category': 'semiconductors', 'severity': 'high'},\n",
    "    '2024-07-15': {'event': 'ASML Export Restrictions', 'color': '#9467bd', 'category': 'semiconductors', 'severity': 'high'},\n",
    "    '2024-12-02': {'event': 'China Chip Retaliation', 'color': '#9467bd', 'category': 'semiconductors', 'severity': 'high'},\n",
    "    '2025-03-18': {'event': 'Enhanced Chip Restrictions', 'color': '#9467bd', 'category': 'semiconductors', 'severity': 'high'},\n",
    "    \n",
    "    # Israel-Iran\n",
    "    '2023-10-07': {'event': 'Hamas Attack on Israel', 'color': '#d62728', 'category': 'israel', 'severity': 'critical'},\n",
    "    '2023-10-27': {'event': 'Israel Ground Invasion Gaza', 'color': '#ff7f0e', 'category': 'israel', 'severity': 'high'},\n",
    "    '2024-04-13': {'event': 'Iran Drone Attack on Israel', 'color': '#d62728', 'category': 'israel', 'severity': 'critical'},\n",
    "    '2024-10-01': {'event': 'Iran Ballistic Missile Attack', 'color': '#d62728', 'category': 'israel', 'severity': 'critical'},\n",
    "    '2024-10-26': {'event': 'Israel Strikes Iran', 'color': '#ff7f0e', 'category': 'israel', 'severity': 'high'},\n",
    "    '2025-01-15': {'event': 'Gaza Ceasefire Agreement', 'color': '#2ca02c', 'category': 'israel', 'severity': 'high'},\n",
    "    \n",
    "    # Ukraine-Russia\n",
    "    '2023-06-06': {'event': 'Kakhovka Dam Destruction', 'color': '#d62728', 'category': 'ukraine', 'severity': 'high'},\n",
    "    '2023-06-24': {'event': 'Wagner Mutiny', 'color': '#ff7f0e', 'category': 'ukraine', 'severity': 'high'},\n",
    "    '2024-02-16': {'event': 'Navalny Death', 'color': '#d62728', 'category': 'ukraine', 'severity': 'high'},\n",
    "    '2024-08-06': {'event': 'Ukraine Kursk Incursion', 'color': '#1f77b4', 'category': 'ukraine', 'severity': 'high'},\n",
    "    '2024-11-19': {'event': 'Russia ICBM Strike Ukraine', 'color': '#d62728', 'category': 'ukraine', 'severity': 'critical'},\n",
    "    '2025-03-01': {'event': 'Trump-Zelensky Meeting', 'color': '#17becf', 'category': 'ukraine', 'severity': 'high'},\n",
    "    \n",
    "    # Other Major Events\n",
    "    '2023-08-24': {'event': 'BRICS Expansion Announced', 'color': '#e377c2', 'category': 'other', 'severity': 'medium'},\n",
    "    '2024-01-13': {'event': 'Taiwan Election', 'color': '#e377c2', 'category': 'other', 'severity': 'high'},\n",
    "    '2024-07-21': {'event': 'Biden Drops Out', 'color': '#1f77b4', 'category': 'other', 'severity': 'high'},\n",
    "    '2024-12-04': {'event': 'South Korea Martial Law', 'color': '#d62728', 'category': 'other', 'severity': 'high'},\n",
    "    '2024-12-08': {'event': 'Syria Assad Falls', 'color': '#d62728', 'category': 'other', 'severity': 'high'},\n",
    "}\n",
    "\n",
    "# Count by category\n",
    "categories = {}\n",
    "for date, info in GEOPOLITICAL_EVENTS.items():\n",
    "    cat = info['category']\n",
    "    categories[cat] = categories.get(cat, 0) + 1\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(GEOPOLITICAL_EVENTS)} geopolitical events:\")\n",
    "for cat, count in sorted(categories.items(), key=lambda x: -x[1]):\n",
    "    print(f\"   ‚Ä¢ {cat}: {count} events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5Ô∏è‚É£ Data Download Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_tickers(tickers: dict, period: str = \"2y\", show_progress: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Download price data for a dictionary of tickers.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    tickers : dict\n",
    "        Dictionary of {name: ticker_symbol}\n",
    "    period : str\n",
    "        Download period (e.g., '1y', '2y', '5y')\n",
    "    show_progress : bool\n",
    "        Whether to show download progress\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with prices for each ticker\n",
    "    \"\"\"\n",
    "    all_data = {}\n",
    "    \n",
    "    for name, ticker in tickers.items():\n",
    "        try:\n",
    "            if show_progress:\n",
    "                print(f\"  üì• {name}...\", end=\" \")\n",
    "            \n",
    "            df = yf.download(ticker, period=period, progress=False, timeout=10)\n",
    "            \n",
    "            if not df.empty and len(df) > 20:\n",
    "                col = 'Adj Close' if 'Adj Close' in df.columns else 'Close'\n",
    "                all_data[name] = df[col].squeeze()\n",
    "                if show_progress:\n",
    "                    print(\"‚úì\")\n",
    "            else:\n",
    "                if show_progress:\n",
    "                    print(\"‚úó (no data)\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            if show_progress:\n",
    "                print(f\"‚úó ({str(e)[:20]}...)\")\n",
    "            \n",
    "            # Try ETF alternative\n",
    "            if name in ETF_ALTERNATIVES:\n",
    "                try:\n",
    "                    alt = ETF_ALTERNATIVES[name]\n",
    "                    df = yf.download(alt, period=period, progress=False)\n",
    "                    if not df.empty:\n",
    "                        all_data[name] = df['Adj Close'].squeeze()\n",
    "                        if show_progress:\n",
    "                            print(f\"      ‚Üí Using {alt} ‚úì\")\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    result = pd.DataFrame(all_data)\n",
    "    result.index = pd.to_datetime(result.index)\n",
    "    return result.ffill(limit=5)\n",
    "\n",
    "\n",
    "def download_all_data(period: str = \"2y\") -> dict:\n",
    "    \"\"\"\n",
    "    Download all required market data.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing indices, factors, volatility, and sectors DataFrames\n",
    "    \"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"üìä DOWNLOADING MARKET DATA\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    data = {}\n",
    "    \n",
    "    print(\"\\nüåç International Indices:\")\n",
    "    data['indices'] = download_tickers(INDEX_TICKERS, period)\n",
    "    \n",
    "    print(\"\\nüéØ Factor ETFs:\")\n",
    "    data['factors'] = download_tickers(FACTOR_TICKERS, period)\n",
    "    \n",
    "    print(\"\\nüìâ Volatility Indices:\")\n",
    "    data['volatility'] = download_tickers(VOLATILITY_TICKERS, period)\n",
    "    \n",
    "    print(\"\\nüìà Sector ETFs:\")\n",
    "    data['sectors'] = download_tickers(SECTOR_TICKERS, period)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"‚úÖ DATA DOWNLOAD COMPLETE\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6Ô∏è‚É£ Download Data\n",
    "\n",
    "‚è±Ô∏è This may take 1-2 minutes depending on your connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìä DOWNLOADING MARKET DATA\n",
      "======================================================================\n",
      "\n",
      "üåç International Indices:\n",
      "  üì• SPY... ‚úì\n",
      "  üì• France... ‚úì\n",
      "  üì• Germany... ‚úì\n",
      "  üì• UK... ‚úì\n",
      "  üì• Italy... ‚úì\n",
      "  üì• Sweden... ‚úì\n",
      "  üì• Spain... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$^OBX: possibly delisted; no price data found  (period=2y)\n",
      "\n",
      "1 Failed download:\n",
      "['^OBX']: possibly delisted; no price data found  (period=2y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì\n",
      "  üì• Norway... ‚úó (no data)\n",
      "  üì• Denmark... ‚úì\n",
      "  üì• Switzerland... ‚úì\n",
      "  üì• Finland... ‚úì\n",
      "  üì• Korea... ‚úì\n",
      "  üì• Japan... ‚úì\n",
      "  üì• China... ‚úì\n",
      "  üì• Hong Kong... ‚úì\n",
      "  üì• Canada... ‚úì\n",
      "  üì• Australia... ‚úì\n",
      "\n",
      "üéØ Factor ETFs:\n",
      "  üì• Market... ‚úì\n",
      "  üì• Value... ‚úì\n",
      "  üì• Growth... ‚úì\n",
      "  üì• Momentum... ‚úì\n",
      "  üì• Quality... ‚úì\n",
      "  üì• Size... ‚úì\n",
      "  üì• Low Vol... ‚úì\n",
      "\n",
      "üìâ Volatility Indices:\n",
      "  üì• VIX... ‚úì\n",
      "  üì• VIX9D... ‚úì\n",
      "  üì• VIX3M... ‚úì\n",
      "  üì• VIX6M... ‚úì\n",
      "  üì• VVIX... ‚úì\n",
      "\n",
      "üìà Sector ETFs:\n",
      "  üì• US Tech... ‚úì\n",
      "  üì• US Semiconductors... ‚úì\n",
      "  üì• US Utilities... ‚úì\n",
      "  üì• US Healthcare... ‚úì\n",
      "  üì• Gold... ‚úì\n",
      "\n",
      "======================================================================\n",
      "‚úÖ DATA DOWNLOAD COMPLETE\n",
      "======================================================================\n",
      "\n",
      "üìä Data Summary:\n",
      "   ‚Ä¢ Indices: 16 countries\n",
      "   ‚Ä¢ Date range: 2024-01-23 to 2026-01-23\n",
      "   ‚Ä¢ Trading days: 522\n"
     ]
    }
   ],
   "source": [
    "# Download all data (2 years)\n",
    "data = download_all_data(period=\"2y\")\n",
    "\n",
    "# Extract DataFrames\n",
    "prices = data['indices']\n",
    "factor_prices = data['factors']\n",
    "vol_data = data['volatility']\n",
    "sector_prices = data['sectors']\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nüìä Data Summary:\")\n",
    "print(f\"   ‚Ä¢ Indices: {len(prices.columns)} countries\")\n",
    "print(f\"   ‚Ä¢ Date range: {prices.index.min().strftime('%Y-%m-%d')} to {prices.index.max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"   ‚Ä¢ Trading days: {len(prices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7Ô∏è‚É£ Calculate Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Calculating returns...\n",
      "   ‚Ä¢ Daily returns: 520 observations\n",
      "   ‚Ä¢ Weekly returns: 104 observations\n",
      "\n",
      "‚úÖ Returns calculated!\n"
     ]
    }
   ],
   "source": [
    "def calculate_returns(prices: pd.DataFrame, frequency: str = 'daily') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate percentage returns at specified frequency.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    prices : pd.DataFrame\n",
    "        Price data\n",
    "    frequency : str\n",
    "        'daily', 'weekly', or 'monthly'\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Returns in percentage terms\n",
    "    \"\"\"\n",
    "    if frequency == 'weekly':\n",
    "        prices = prices.resample('W-FRI').last()\n",
    "    elif frequency == 'monthly':\n",
    "        prices = prices.resample('M').last()\n",
    "    \n",
    "    return prices.pct_change().dropna() * 100\n",
    "\n",
    "\n",
    "def calculate_realized_volatility(returns: pd.Series, window: int = 21) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Calculate annualized realized volatility.\n",
    "    \"\"\"\n",
    "    return returns.rolling(window).std() * np.sqrt(252)\n",
    "\n",
    "\n",
    "# Calculate returns\n",
    "print(\"üìà Calculating returns...\")\n",
    "\n",
    "daily_returns = calculate_returns(prices, 'daily')\n",
    "weekly_returns = calculate_returns(prices, 'weekly')\n",
    "factor_returns = calculate_returns(factor_prices, 'weekly')\n",
    "\n",
    "print(f\"   ‚Ä¢ Daily returns: {len(daily_returns)} observations\")\n",
    "print(f\"   ‚Ä¢ Weekly returns: {len(weekly_returns)} observations\")\n",
    "print(f\"\\n‚úÖ Returns calculated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8Ô∏è‚É£ Basic Statistics & Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä COUNTRY STATISTICS (Sorted by Sharpe Ratio)\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Region",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Beta",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Alpha (%)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R¬≤",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Correlation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Avg Weekly (%)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Weekly Vol (%)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Ann. Return (%)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Ann. Vol (%)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Sharpe",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "VaR 95% (%)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CVaR 95% (%)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Max DD (%)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Skewness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Kurtosis",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "3e113873-ec0d-4ac1-9152-d39001879b33",
       "rows": [
        [
         "13",
         "Canada",
         "North America",
         "0.535",
         "0.243",
         "0.563",
         "0.75",
         "0.445",
         "1.471",
         "23.13",
         "10.61",
         "2.18",
         "-1.99",
         "-3.087",
         "-9.724",
         "-0.988",
         "3.678"
        ],
        [
         "5",
         "Spain",
         "Southern Europe",
         "0.476",
         "0.389",
         "0.231",
         "0.48",
         "0.569",
         "2.045",
         "29.582",
         "14.749",
         "2.006",
         "-2.683",
         "-3.931",
         "-7.971",
         "-0.483",
         "0.784"
        ],
        [
         "9",
         "Korea",
         "Asia Developed",
         "0.553",
         "0.499",
         "0.192",
         "0.438",
         "0.709",
         "2.604",
         "36.846",
         "18.78",
         "1.962",
         "-3.62",
         "-4.399",
         "-16.004",
         "-0.125",
         "-0.384"
        ],
        [
         "2",
         "UK",
         "Western Europe",
         "0.358",
         "0.148",
         "0.264",
         "0.514",
         "0.284",
         "1.439",
         "14.759",
         "10.377",
         "1.422",
         "-1.424",
         "-2.742",
         "-9.597",
         "-0.888",
         "5.422"
        ],
        [
         "1",
         "Germany",
         "Western Europe",
         "0.579",
         "0.172",
         "0.34",
         "0.583",
         "0.391",
         "2.049",
         "20.321",
         "14.777",
         "1.375",
         "-3.181",
         "-4.201",
         "-11.451",
         "-0.639",
         "1.998"
        ],
        [
         "3",
         "Italy",
         "Southern Europe",
         "0.559",
         "0.191",
         "0.244",
         "0.494",
         "0.402",
         "2.334",
         "20.921",
         "16.828",
         "1.243",
         "-3.13",
         "-5.208",
         "-12.829",
         "-1.254",
         "4.003"
        ],
        [
         "12",
         "Hong Kong",
         "Asia Developed",
         "0.366",
         "0.41",
         "0.055",
         "0.235",
         "0.549",
         "3.216",
         "28.535",
         "23.191",
         "1.23",
         "-4.664",
         "-5.998",
         "-16.153",
         "0.535",
         "2.473"
        ],
        [
         "11",
         "China",
         "Asia Emerging",
         "0.188",
         "0.295",
         "0.027",
         "0.164",
         "0.366",
         "2.373",
         "19.023",
         "17.109",
         "1.112",
         "-3.099",
         "-4.304",
         "-14.28",
         "1.438",
         "7.924"
        ],
        [
         "10",
         "Japan",
         "Asia Developed",
         "0.813",
         "0.127",
         "0.344",
         "0.587",
         "0.435",
         "2.863",
         "22.633",
         "20.647",
         "1.096",
         "-4.165",
         "-5.979",
         "-18.463",
         "-0.247",
         "0.873"
        ],
        [
         "8",
         "Finland",
         "Northern Europe",
         "0.445",
         "0.084",
         "0.239",
         "0.489",
         "0.253",
         "1.882",
         "13.148",
         "13.569",
         "0.969",
         "-2.424",
         "-3.845",
         "-13.522",
         "-0.49",
         "2.072"
        ],
        [
         "4",
         "Sweden",
         "Northern Europe",
         "0.672",
         "-0.001",
         "0.442",
         "0.665",
         "0.253",
         "2.087",
         "13.163",
         "15.052",
         "0.874",
         "-2.752",
         "-4.682",
         "-16.547",
         "-1.184",
         "4.727"
        ],
        [
         "14",
         "Australia",
         "Oceania",
         "0.386",
         "0.017",
         "0.325",
         "0.57",
         "0.163",
         "1.399",
         "8.476",
         "10.085",
         "0.84",
         "-2.484",
         "-2.972",
         "-10.628",
         "-0.419",
         "0.074"
        ],
        [
         "7",
         "Switzerland",
         "Western Europe",
         "0.437",
         "-0.009",
         "0.225",
         "0.474",
         "0.156",
         "1.903",
         "8.122",
         "13.72",
         "0.592",
         "-2.589",
         "-4.222",
         "-14.047",
         "-1.068",
         "5.007"
        ],
        [
         "0",
         "France",
         "Western Europe",
         "0.542",
         "-0.123",
         "0.304",
         "0.552",
         "0.083",
         "2.03",
         "4.3",
         "14.637",
         "0.294",
         "-3.317",
         "-4.756",
         "-13.558",
         "-0.813",
         "2.074"
        ],
        [
         "6",
         "Denmark",
         "Northern Europe",
         "0.612",
         "-0.162",
         "0.277",
         "0.526",
         "0.069",
         "2.401",
         "3.609",
         "17.312",
         "0.208",
         "-2.793",
         "-5.723",
         "-25.724",
         "-1.06",
         "4.944"
        ]
       ],
       "shape": {
        "columns": 16,
        "rows": 15
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Alpha (%)</th>\n",
       "      <th>R¬≤</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>Avg Weekly (%)</th>\n",
       "      <th>Weekly Vol (%)</th>\n",
       "      <th>Ann. Return (%)</th>\n",
       "      <th>Ann. Vol (%)</th>\n",
       "      <th>Sharpe</th>\n",
       "      <th>VaR 95% (%)</th>\n",
       "      <th>CVaR 95% (%)</th>\n",
       "      <th>Max DD (%)</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Canada</td>\n",
       "      <td>North America</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.445</td>\n",
       "      <td>1.471</td>\n",
       "      <td>23.130</td>\n",
       "      <td>10.610</td>\n",
       "      <td>2.180</td>\n",
       "      <td>-1.990</td>\n",
       "      <td>-3.087</td>\n",
       "      <td>-9.724</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>3.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Southern Europe</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.569</td>\n",
       "      <td>2.045</td>\n",
       "      <td>29.582</td>\n",
       "      <td>14.749</td>\n",
       "      <td>2.006</td>\n",
       "      <td>-2.683</td>\n",
       "      <td>-3.931</td>\n",
       "      <td>-7.971</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Korea</td>\n",
       "      <td>Asia Developed</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.709</td>\n",
       "      <td>2.604</td>\n",
       "      <td>36.846</td>\n",
       "      <td>18.780</td>\n",
       "      <td>1.962</td>\n",
       "      <td>-3.620</td>\n",
       "      <td>-4.399</td>\n",
       "      <td>-16.004</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UK</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.284</td>\n",
       "      <td>1.439</td>\n",
       "      <td>14.759</td>\n",
       "      <td>10.377</td>\n",
       "      <td>1.422</td>\n",
       "      <td>-1.424</td>\n",
       "      <td>-2.742</td>\n",
       "      <td>-9.597</td>\n",
       "      <td>-0.888</td>\n",
       "      <td>5.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.391</td>\n",
       "      <td>2.049</td>\n",
       "      <td>20.321</td>\n",
       "      <td>14.777</td>\n",
       "      <td>1.375</td>\n",
       "      <td>-3.181</td>\n",
       "      <td>-4.201</td>\n",
       "      <td>-11.451</td>\n",
       "      <td>-0.639</td>\n",
       "      <td>1.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Southern Europe</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.402</td>\n",
       "      <td>2.334</td>\n",
       "      <td>20.921</td>\n",
       "      <td>16.828</td>\n",
       "      <td>1.243</td>\n",
       "      <td>-3.130</td>\n",
       "      <td>-5.208</td>\n",
       "      <td>-12.829</td>\n",
       "      <td>-1.254</td>\n",
       "      <td>4.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>Asia Developed</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.549</td>\n",
       "      <td>3.216</td>\n",
       "      <td>28.535</td>\n",
       "      <td>23.191</td>\n",
       "      <td>1.230</td>\n",
       "      <td>-4.664</td>\n",
       "      <td>-5.998</td>\n",
       "      <td>-16.153</td>\n",
       "      <td>0.535</td>\n",
       "      <td>2.473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>China</td>\n",
       "      <td>Asia Emerging</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.366</td>\n",
       "      <td>2.373</td>\n",
       "      <td>19.023</td>\n",
       "      <td>17.109</td>\n",
       "      <td>1.112</td>\n",
       "      <td>-3.099</td>\n",
       "      <td>-4.304</td>\n",
       "      <td>-14.280</td>\n",
       "      <td>1.438</td>\n",
       "      <td>7.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Asia Developed</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.435</td>\n",
       "      <td>2.863</td>\n",
       "      <td>22.633</td>\n",
       "      <td>20.647</td>\n",
       "      <td>1.096</td>\n",
       "      <td>-4.165</td>\n",
       "      <td>-5.979</td>\n",
       "      <td>-18.463</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>0.873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Finland</td>\n",
       "      <td>Northern Europe</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.253</td>\n",
       "      <td>1.882</td>\n",
       "      <td>13.148</td>\n",
       "      <td>13.569</td>\n",
       "      <td>0.969</td>\n",
       "      <td>-2.424</td>\n",
       "      <td>-3.845</td>\n",
       "      <td>-13.522</td>\n",
       "      <td>-0.490</td>\n",
       "      <td>2.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>Northern Europe</td>\n",
       "      <td>0.672</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.253</td>\n",
       "      <td>2.087</td>\n",
       "      <td>13.163</td>\n",
       "      <td>15.052</td>\n",
       "      <td>0.874</td>\n",
       "      <td>-2.752</td>\n",
       "      <td>-4.682</td>\n",
       "      <td>-16.547</td>\n",
       "      <td>-1.184</td>\n",
       "      <td>4.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.163</td>\n",
       "      <td>1.399</td>\n",
       "      <td>8.476</td>\n",
       "      <td>10.085</td>\n",
       "      <td>0.840</td>\n",
       "      <td>-2.484</td>\n",
       "      <td>-2.972</td>\n",
       "      <td>-10.628</td>\n",
       "      <td>-0.419</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>0.437</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.156</td>\n",
       "      <td>1.903</td>\n",
       "      <td>8.122</td>\n",
       "      <td>13.720</td>\n",
       "      <td>0.592</td>\n",
       "      <td>-2.589</td>\n",
       "      <td>-4.222</td>\n",
       "      <td>-14.047</td>\n",
       "      <td>-1.068</td>\n",
       "      <td>5.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>0.542</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.083</td>\n",
       "      <td>2.030</td>\n",
       "      <td>4.300</td>\n",
       "      <td>14.637</td>\n",
       "      <td>0.294</td>\n",
       "      <td>-3.317</td>\n",
       "      <td>-4.756</td>\n",
       "      <td>-13.558</td>\n",
       "      <td>-0.813</td>\n",
       "      <td>2.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>Northern Europe</td>\n",
       "      <td>0.612</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.069</td>\n",
       "      <td>2.401</td>\n",
       "      <td>3.609</td>\n",
       "      <td>17.312</td>\n",
       "      <td>0.208</td>\n",
       "      <td>-2.793</td>\n",
       "      <td>-5.723</td>\n",
       "      <td>-25.724</td>\n",
       "      <td>-1.060</td>\n",
       "      <td>4.944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Country           Region   Beta  Alpha (%)     R¬≤  Correlation  \\\n",
       "13       Canada    North America  0.535      0.243  0.563        0.750   \n",
       "5         Spain  Southern Europe  0.476      0.389  0.231        0.480   \n",
       "9         Korea   Asia Developed  0.553      0.499  0.192        0.438   \n",
       "2            UK   Western Europe  0.358      0.148  0.264        0.514   \n",
       "1       Germany   Western Europe  0.579      0.172  0.340        0.583   \n",
       "3         Italy  Southern Europe  0.559      0.191  0.244        0.494   \n",
       "12    Hong Kong   Asia Developed  0.366      0.410  0.055        0.235   \n",
       "11        China    Asia Emerging  0.188      0.295  0.027        0.164   \n",
       "10        Japan   Asia Developed  0.813      0.127  0.344        0.587   \n",
       "8       Finland  Northern Europe  0.445      0.084  0.239        0.489   \n",
       "4        Sweden  Northern Europe  0.672     -0.001  0.442        0.665   \n",
       "14    Australia          Oceania  0.386      0.017  0.325        0.570   \n",
       "7   Switzerland   Western Europe  0.437     -0.009  0.225        0.474   \n",
       "0        France   Western Europe  0.542     -0.123  0.304        0.552   \n",
       "6       Denmark  Northern Europe  0.612     -0.162  0.277        0.526   \n",
       "\n",
       "    Avg Weekly (%)  Weekly Vol (%)  Ann. Return (%)  Ann. Vol (%)  Sharpe  \\\n",
       "13           0.445           1.471           23.130        10.610   2.180   \n",
       "5            0.569           2.045           29.582        14.749   2.006   \n",
       "9            0.709           2.604           36.846        18.780   1.962   \n",
       "2            0.284           1.439           14.759        10.377   1.422   \n",
       "1            0.391           2.049           20.321        14.777   1.375   \n",
       "3            0.402           2.334           20.921        16.828   1.243   \n",
       "12           0.549           3.216           28.535        23.191   1.230   \n",
       "11           0.366           2.373           19.023        17.109   1.112   \n",
       "10           0.435           2.863           22.633        20.647   1.096   \n",
       "8            0.253           1.882           13.148        13.569   0.969   \n",
       "4            0.253           2.087           13.163        15.052   0.874   \n",
       "14           0.163           1.399            8.476        10.085   0.840   \n",
       "7            0.156           1.903            8.122        13.720   0.592   \n",
       "0            0.083           2.030            4.300        14.637   0.294   \n",
       "6            0.069           2.401            3.609        17.312   0.208   \n",
       "\n",
       "    VaR 95% (%)  CVaR 95% (%)  Max DD (%)  Skewness  Kurtosis  \n",
       "13       -1.990        -3.087      -9.724    -0.988     3.678  \n",
       "5        -2.683        -3.931      -7.971    -0.483     0.784  \n",
       "9        -3.620        -4.399     -16.004    -0.125    -0.384  \n",
       "2        -1.424        -2.742      -9.597    -0.888     5.422  \n",
       "1        -3.181        -4.201     -11.451    -0.639     1.998  \n",
       "3        -3.130        -5.208     -12.829    -1.254     4.003  \n",
       "12       -4.664        -5.998     -16.153     0.535     2.473  \n",
       "11       -3.099        -4.304     -14.280     1.438     7.924  \n",
       "10       -4.165        -5.979     -18.463    -0.247     0.873  \n",
       "8        -2.424        -3.845     -13.522    -0.490     2.072  \n",
       "4        -2.752        -4.682     -16.547    -1.184     4.727  \n",
       "14       -2.484        -2.972     -10.628    -0.419     0.074  \n",
       "7        -2.589        -4.222     -14.047    -1.068     5.007  \n",
       "0        -3.317        -4.756     -13.558    -0.813     2.074  \n",
       "6        -2.793        -5.723     -25.724    -1.060     4.944  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_comprehensive_stats(returns: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate comprehensive statistics for all countries.\n",
    "    \"\"\"\n",
    "    stats_list = []\n",
    "    \n",
    "    for country in returns.columns:\n",
    "        if country == 'SPY':\n",
    "            continue\n",
    "        \n",
    "        ret = returns[country].dropna()\n",
    "        spy = returns['SPY'].loc[ret.index] if 'SPY' in returns.columns else None\n",
    "        \n",
    "        if len(ret) < 20:\n",
    "            continue\n",
    "        \n",
    "        row = {\n",
    "            'Country': country,\n",
    "            'Region': COUNTRY_TO_REGION.get(country, 'Unknown'),\n",
    "        }\n",
    "        \n",
    "        # Regression with SPY\n",
    "        if spy is not None and len(spy) > 20:\n",
    "            slope, intercept, r_val, p_val, std_err = stats.linregress(spy, ret)\n",
    "            row.update({\n",
    "                'Beta': slope,\n",
    "                'Alpha (%)': intercept,\n",
    "                'R¬≤': r_val ** 2,\n",
    "                'Correlation': r_val,\n",
    "            })\n",
    "        \n",
    "        # Return stats\n",
    "        row.update({\n",
    "            'Avg Weekly (%)': ret.mean(),\n",
    "            'Weekly Vol (%)': ret.std(),\n",
    "            'Ann. Return (%)': ret.mean() * 52,\n",
    "            'Ann. Vol (%)': ret.std() * np.sqrt(52),\n",
    "            'Sharpe': (ret.mean() * 52) / (ret.std() * np.sqrt(52)) if ret.std() > 0 else 0,\n",
    "        })\n",
    "        \n",
    "        # Risk metrics\n",
    "        var_95 = np.percentile(ret, 5)\n",
    "        cvar_95 = ret[ret <= var_95].mean()\n",
    "        \n",
    "        cumret = (1 + ret / 100).cumprod()\n",
    "        max_dd = ((cumret / cumret.expanding().max()) - 1).min() * 100\n",
    "        \n",
    "        row.update({\n",
    "            'VaR 95% (%)': var_95,\n",
    "            'CVaR 95% (%)': cvar_95,\n",
    "            'Max DD (%)': max_dd,\n",
    "            'Skewness': ret.skew(),\n",
    "            'Kurtosis': ret.kurtosis(),\n",
    "        })\n",
    "        \n",
    "        stats_list.append(row)\n",
    "    \n",
    "    return pd.DataFrame(stats_list)\n",
    "\n",
    "\n",
    "# Calculate statistics\n",
    "stats_df = calculate_comprehensive_stats(weekly_returns)\n",
    "stats_df = stats_df.sort_values('Sharpe', ascending=False)\n",
    "\n",
    "# Display\n",
    "print(\"üìä COUNTRY STATISTICS (Sorted by Sharpe Ratio)\")\n",
    "print(\"=\" * 80)\n",
    "display(stats_df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üìä SECTION A: Options-Implied Volatility Analysis\n",
    "\n",
    "Analyzing VIX term structure, IV-RV spread, and volatility risk premium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Analyzing Implied Volatility...\n",
      "\n",
      "üìâ VIX Summary:\n",
      "   ‚Ä¢ Current: 16.1\n",
      "   ‚Ä¢ Mean: 17.4\n",
      "   ‚Ä¢ Min/Max: 11.9 / 52.3\n",
      "   ‚Ä¢ 90th Percentile: 22.3\n",
      "\n",
      "üí∞ Volatility Risk Premium:\n",
      "   ‚Ä¢ Current: 5.9%\n",
      "   ‚Ä¢ Mean: 3.6%\n",
      "   ‚Ä¢ Positive 85% of the time\n"
     ]
    }
   ],
   "source": [
    "def analyze_implied_volatility(vol_data: pd.DataFrame, spy_returns: pd.Series) -> dict:\n",
    "    \"\"\"\n",
    "    Comprehensive implied volatility analysis.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict containing:\n",
    "        - vix_stats: VIX summary statistics\n",
    "        - vix_percentile: Rolling percentile rank\n",
    "        - iv_rv_spread: IV minus RV spread\n",
    "        - vrp_stats: Volatility risk premium stats\n",
    "        - term_structure: VIX term structure data\n",
    "        - contango: Term structure slope\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    if 'VIX' not in vol_data.columns:\n",
    "        print(\"‚ö†Ô∏è VIX data not available\")\n",
    "        return results\n",
    "    \n",
    "    vix = vol_data['VIX'].dropna()\n",
    "    \n",
    "    # VIX Statistics\n",
    "    results['vix_stats'] = {\n",
    "        'current': vix.iloc[-1] if len(vix) > 0 else np.nan,\n",
    "        'mean': vix.mean(),\n",
    "        'median': vix.median(),\n",
    "        'std': vix.std(),\n",
    "        'min': vix.min(),\n",
    "        'max': vix.max(),\n",
    "        'pct_25': vix.quantile(0.25),\n",
    "        'pct_75': vix.quantile(0.75),\n",
    "        'pct_90': vix.quantile(0.90),\n",
    "        'pct_95': vix.quantile(0.95),\n",
    "    }\n",
    "    \n",
    "    # VIX Percentile (1-year rolling)\n",
    "    results['vix_percentile'] = vix.rolling(252).apply(\n",
    "        lambda x: stats.percentileofscore(x, x.iloc[-1]) if len(x) > 50 else np.nan\n",
    "    )\n",
    "    \n",
    "    # IV-RV Spread (Volatility Risk Premium)\n",
    "    rv = calculate_realized_volatility(spy_returns, window=21)\n",
    "    common_idx = vix.index.intersection(rv.index)\n",
    "    \n",
    "    if len(common_idx) > 50:\n",
    "        results['iv_rv_spread'] = pd.DataFrame({\n",
    "            'VIX': vix.loc[common_idx],\n",
    "            'Realized Vol': rv.loc[common_idx],\n",
    "            'Spread': vix.loc[common_idx] - rv.loc[common_idx]\n",
    "        })\n",
    "        results['vrp_stats'] = {\n",
    "            'mean': results['iv_rv_spread']['Spread'].mean(),\n",
    "            'current': results['iv_rv_spread']['Spread'].iloc[-1],\n",
    "            'pct_positive': (results['iv_rv_spread']['Spread'] > 0).mean() * 100\n",
    "        }\n",
    "    \n",
    "    # Term Structure\n",
    "    term_cols = ['VIX9D', 'VIX', 'VIX3M', 'VIX6M']\n",
    "    available = [c for c in term_cols if c in vol_data.columns]\n",
    "    if len(available) > 1:\n",
    "        results['term_structure'] = vol_data[available].dropna()\n",
    "        \n",
    "        # Contango/Backwardation (3M - 1M slope)\n",
    "        if 'VIX3M' in vol_data.columns:\n",
    "            spread = vol_data['VIX3M'] - vol_data['VIX']\n",
    "            results['contango'] = spread\n",
    "            results['contango_pct'] = (spread > 0).mean() * 100\n",
    "    \n",
    "    # VVIX\n",
    "    if 'VVIX' in vol_data.columns:\n",
    "        results['vvix'] = vol_data['VVIX'].dropna()\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Run analysis\n",
    "print(\"üìä Analyzing Implied Volatility...\")\n",
    "vol_analysis = analyze_implied_volatility(vol_data, daily_returns.get('SPY', pd.Series()))\n",
    "\n",
    "# Display summary\n",
    "if 'vix_stats' in vol_analysis:\n",
    "    vs = vol_analysis['vix_stats']\n",
    "    print(f\"\\nüìâ VIX Summary:\")\n",
    "    print(f\"   ‚Ä¢ Current: {vs['current']:.1f}\")\n",
    "    print(f\"   ‚Ä¢ Mean: {vs['mean']:.1f}\")\n",
    "    print(f\"   ‚Ä¢ Min/Max: {vs['min']:.1f} / {vs['max']:.1f}\")\n",
    "    print(f\"   ‚Ä¢ 90th Percentile: {vs['pct_90']:.1f}\")\n",
    "\n",
    "if 'vrp_stats' in vol_analysis:\n",
    "    vrp = vol_analysis['vrp_stats']\n",
    "    print(f\"\\nüí∞ Volatility Risk Premium:\")\n",
    "    print(f\"   ‚Ä¢ Current: {vrp['current']:.1f}%\")\n",
    "    print(f\"   ‚Ä¢ Mean: {vrp['mean']:.1f}%\")\n",
    "    print(f\"   ‚Ä¢ Positive {vrp['pct_positive']:.0f}% of the time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create Implied Volatility Dashboard\ndef create_implied_vol_dashboard(vol_analysis: dict, vol_data: pd.DataFrame,\n                                  spy_returns: pd.Series, events: dict) -> go.Figure:\n    \"\"\"\n    Create comprehensive implied volatility dashboard.\n    \"\"\"\n    fig = make_subplots(\n        rows=3, cols=2,\n        subplot_titles=(\n            'VIX Term Structure Over Time',\n            'VIX Distribution',\n            'Implied vs Realized Volatility',\n            'Volatility Risk Premium (IV - RV)',\n            'VIX Percentile Rank (1-Year Rolling)',\n            'VIX Regime Classification'\n        ),\n        vertical_spacing=0.1,\n        horizontal_spacing=0.08,\n        specs=[[{'type': 'scatter'}, {'type': 'histogram'}],\n               [{'type': 'scatter'}, {'type': 'scatter'}],\n               [{'type': 'scatter'}, {'type': 'domain'}]]\n    )\n    \n    vix = vol_data.get('VIX', pd.Series())\n    if vix.empty:\n        return fig\n    vix = vix.dropna()\n    \n    # 1. Term Structure\n    colors = {'VIX9D': '#ff7f0e', 'VIX': '#d62728', 'VIX3M': '#1f77b4', 'VIX6M': '#2ca02c'}\n    for col in ['VIX9D', 'VIX', 'VIX3M', 'VIX6M']:\n        if col in vol_data.columns:\n            series = vol_data[col].dropna()\n            fig.add_trace(go.Scatter(\n                x=series.index, y=series,\n                mode='lines', name=col,\n                line=dict(color=colors.get(col), width=1.5)\n            ), row=1, col=1)\n    \n    # Add regime bands\n    for y0, y1, color, label in [(0, 15, 'green', 'Low'), (15, 20, 'yellow', 'Normal'),\n                                  (20, 30, 'orange', 'Elevated'), (30, 80, 'red', 'High')]:\n        fig.add_hrect(y0=y0, y1=y1, fillcolor=color, opacity=0.1, row=1, col=1)\n    \n    # 2. VIX Distribution\n    fig.add_trace(go.Histogram(\n        x=vix, nbinsx=50, name='VIX',\n        marker_color='#1f77b4', opacity=0.7, showlegend=False\n    ), row=1, col=2)\n    fig.add_vline(x=vix.mean(), line_dash=\"dash\", line_color=\"red\", row=1, col=2)\n    fig.add_vline(x=vix.iloc[-1], line_dash=\"solid\", line_color=\"green\", row=1, col=2)\n    \n    # 3. IV vs RV\n    if 'iv_rv_spread' in vol_analysis:\n        spread_df = vol_analysis['iv_rv_spread']\n        fig.add_trace(go.Scatter(\n            x=spread_df.index, y=spread_df['VIX'],\n            mode='lines', name='Implied (VIX)',\n            line=dict(color='#d62728', width=2)\n        ), row=2, col=1)\n        fig.add_trace(go.Scatter(\n            x=spread_df.index, y=spread_df['Realized Vol'],\n            mode='lines', name='Realized (21d)',\n            line=dict(color='#1f77b4', width=2)\n        ), row=2, col=1)\n        \n        # 4. VRP\n        fig.add_trace(go.Scatter(\n            x=spread_df.index, y=spread_df['Spread'],\n            mode='lines', name='IV-RV Spread',\n            line=dict(color='#2ca02c', width=2),\n            fill='tozeroy', fillcolor='rgba(44, 160, 44, 0.2)',\n            showlegend=False\n        ), row=2, col=2)\n        fig.add_hline(y=0, line_dash=\"solid\", line_color=\"gray\", row=2, col=2)\n        if 'vrp_stats' in vol_analysis:\n            fig.add_hline(y=vol_analysis['vrp_stats']['mean'], line_dash=\"dash\",\n                         line_color=\"red\", row=2, col=2)\n    \n    # 5. VIX Percentile\n    if 'vix_percentile' in vol_analysis:\n        pctl = vol_analysis['vix_percentile'].dropna()\n        fig.add_trace(go.Scatter(\n            x=pctl.index, y=pctl,\n            mode='lines', name='Percentile',\n            line=dict(color='#9467bd', width=2),\n            fill='tozeroy', fillcolor='rgba(148, 103, 189, 0.2)',\n            showlegend=False\n        ), row=3, col=1)\n        fig.add_hline(y=80, line_dash=\"dash\", line_color=\"red\", row=3, col=1)\n        fig.add_hline(y=20, line_dash=\"dash\", line_color=\"green\", row=3, col=1)\n    \n    # 6. Regime Pie - use 'domain' type for pie charts in subplots\n    regime_counts = {\n        'Low (<15)': (vix < 15).sum(),\n        'Normal (15-20)': ((vix >= 15) & (vix < 20)).sum(),\n        'Elevated (20-30)': ((vix >= 20) & (vix < 30)).sum(),\n        'High (>30)': (vix >= 30).sum()\n    }\n    fig.add_trace(go.Pie(\n        labels=list(regime_counts.keys()),\n        values=list(regime_counts.values()),\n        marker_colors=['#2ca02c', '#ffff00', '#ff7f0e', '#d62728'],\n        textinfo='percent+label',\n        hole=0.4,\n        showlegend=False\n    ), row=3, col=2)\n    \n    # Add events - use add_shape instead of add_vline for compatibility with mixed subplot types\n    for date_str, event_info in events.items():\n        event_date = pd.to_datetime(date_str)\n        if vix.index.min() <= event_date <= vix.index.max():\n            if event_info.get('severity') in ['high', 'critical']:\n                # Add vertical line to row 1 col 1 using add_shape\n                fig.add_shape(\n                    type=\"line\",\n                    x0=event_date, x1=event_date,\n                    y0=0, y1=1,\n                    yref='y domain',\n                    line=dict(color=event_info['color'], width=1, dash='dash'),\n                    opacity=0.4,\n                    row=1, col=1\n                )\n                # Add vertical line to row 2 col 1 using add_shape\n                fig.add_shape(\n                    type=\"line\",\n                    x0=event_date, x1=event_date,\n                    y0=0, y1=1,\n                    yref='y3 domain',\n                    line=dict(color=event_info['color'], width=1, dash='dash'),\n                    opacity=0.4,\n                    row=2, col=1\n                )\n    \n    fig.update_layout(\n        title=dict(\n            text='<b>Options-Implied Volatility Analysis</b><br>'\n                 '<sup>VIX Term Structure | IV-RV Spread | Volatility Risk Premium</sup>',\n            x=0.5, font=dict(size=18)\n        ),\n        height=1000, width=1200,\n        showlegend=True,\n        legend=dict(orientation='h', y=1.02),\n        template='plotly_white'\n    )\n    \n    return fig\n\n\n# Create and display\nfig_iv = create_implied_vol_dashboard(\n    vol_analysis, vol_data, \n    daily_returns.get('SPY', pd.Series()), \n    GEOPOLITICAL_EVENTS\n)\nfig_iv.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üîó SECTION B: Correlation Regime Analysis\n",
    "\n",
    "Analyzing how correlations change between low and high volatility regimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_correlation_by_regime(returns: pd.DataFrame, vix: pd.Series,\n",
    "                                     thresholds: tuple = (20, 30)) -> dict:\n",
    "    \"\"\"\n",
    "    Calculate correlation matrices for different VIX regimes.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    returns : pd.DataFrame\n",
    "        Weekly returns\n",
    "    vix : pd.Series\n",
    "        VIX time series\n",
    "    thresholds : tuple\n",
    "        (low_threshold, high_threshold) for regime classification\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict with correlation matrices for each regime\n",
    "    \"\"\"\n",
    "    common_idx = returns.index.intersection(vix.index)\n",
    "    returns_aligned = returns.loc[common_idx]\n",
    "    vix_aligned = vix.loc[common_idx]\n",
    "    \n",
    "    low_vol = vix_aligned < thresholds[0]\n",
    "    mid_vol = (vix_aligned >= thresholds[0]) & (vix_aligned < thresholds[1])\n",
    "    high_vol = vix_aligned >= thresholds[1]\n",
    "    \n",
    "    results = {\n",
    "        'Low VIX (<20)': {\n",
    "            'corr': returns_aligned[low_vol].corr(),\n",
    "            'count': low_vol.sum(),\n",
    "            'pct': low_vol.mean() * 100\n",
    "        },\n",
    "        'Normal VIX (20-30)': {\n",
    "            'corr': returns_aligned[mid_vol].corr(),\n",
    "            'count': mid_vol.sum(),\n",
    "            'pct': mid_vol.mean() * 100\n",
    "        },\n",
    "        'High VIX (>30)': {\n",
    "            'corr': returns_aligned[high_vol].corr(),\n",
    "            'count': high_vol.sum(),\n",
    "            'pct': high_vol.mean() * 100\n",
    "        },\n",
    "        'Full Period': {\n",
    "            'corr': returns_aligned.corr(),\n",
    "            'count': len(returns_aligned),\n",
    "            'pct': 100.0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Correlation change\n",
    "    if low_vol.sum() > 10 and high_vol.sum() > 10:\n",
    "        results['corr_change'] = results['High VIX (>30)']['corr'] - results['Low VIX (<20)']['corr']\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Calculate correlation regimes\n",
    "vix = vol_data.get('VIX', pd.Series())\n",
    "if not vix.empty:\n",
    "    print(\"üîó Calculating correlation regimes...\")\n",
    "    corr_regimes = calculate_correlation_by_regime(weekly_returns, vix)\n",
    "    \n",
    "    print(f\"\\nüìä Regime Distribution:\")\n",
    "    for regime, data in corr_regimes.items():\n",
    "        if regime != 'corr_change' and 'pct' in data:\n",
    "            print(f\"   ‚Ä¢ {regime}: {data['pct']:.1f}% ({data['count']} days)\")\n",
    "else:\n",
    "    corr_regimes = {}\n",
    "    print(\"‚ö†Ô∏è VIX data not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Correlation Regime Heatmaps\n",
    "def create_correlation_regime_heatmaps(corr_regimes: dict) -> go.Figure:\n",
    "    \"\"\"\n",
    "    Create heatmaps for different correlation regimes.\n",
    "    \"\"\"\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=[\n",
    "            f\"Low VIX (<20) - {corr_regimes.get('Low VIX (<20)', {}).get('pct', 0):.1f}% of days\",\n",
    "            f\"High VIX (>30) - {corr_regimes.get('High VIX (>30)', {}).get('pct', 0):.1f}% of days\",\n",
    "            'Correlation CHANGE (High - Low VIX)',\n",
    "            'Full Period Correlation'\n",
    "        ],\n",
    "        horizontal_spacing=0.12,\n",
    "        vertical_spacing=0.15\n",
    "    )\n",
    "    \n",
    "    top_countries = ['SPY', 'Germany', 'UK', 'France', 'Japan', 'China', 'Canada', 'Australia']\n",
    "    \n",
    "    def add_heatmap(corr_matrix, row, col, zmid=0.5, colorscale='RdBu_r'):\n",
    "        if corr_matrix is None or corr_matrix.empty:\n",
    "            return\n",
    "        available = [c for c in top_countries if c in corr_matrix.columns]\n",
    "        if not available:\n",
    "            return\n",
    "        sub = corr_matrix.loc[available, available]\n",
    "        \n",
    "        fig.add_trace(go.Heatmap(\n",
    "            z=sub.values, x=sub.columns, y=sub.index,\n",
    "            colorscale=colorscale, \n",
    "            zmin=-1 if zmid == 0 else 0, \n",
    "            zmax=1,\n",
    "            zmid=zmid,\n",
    "            text=np.round(sub.values, 2),\n",
    "            texttemplate='%{text}',\n",
    "            textfont={\"size\": 9},\n",
    "            showscale=(row == 1 and col == 2)\n",
    "        ), row=row, col=col)\n",
    "    \n",
    "    # Low VIX\n",
    "    if 'Low VIX (<20)' in corr_regimes:\n",
    "        add_heatmap(corr_regimes['Low VIX (<20)']['corr'], 1, 1)\n",
    "    \n",
    "    # High VIX\n",
    "    if 'High VIX (>30)' in corr_regimes:\n",
    "        add_heatmap(corr_regimes['High VIX (>30)']['corr'], 1, 2)\n",
    "    \n",
    "    # Change (Red = correlations increased during stress)\n",
    "    if 'corr_change' in corr_regimes:\n",
    "        add_heatmap(corr_regimes['corr_change'], 2, 1, zmid=0, colorscale='RdYlGn_r')\n",
    "    \n",
    "    # Full period\n",
    "    if 'Full Period' in corr_regimes:\n",
    "        add_heatmap(corr_regimes['Full Period']['corr'], 2, 2)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text='<b>üîó Correlation Matrix by VIX Regime</b><br>'\n",
    "                 '<sup>‚ö†Ô∏è Notice: Correlations INCREASE during high volatility (diversification breakdown)</sup>',\n",
    "            x=0.5, font=dict(size=18)\n",
    "        ),\n",
    "        height=900, width=1100,\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "# Create and display\n",
    "if corr_regimes:\n",
    "    fig_corr = create_correlation_regime_heatmaps(corr_regimes)\n",
    "    fig_corr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Change Bar Chart\n",
    "def create_correlation_change_chart(corr_regimes: dict) -> go.Figure:\n",
    "    \"\"\"\n",
    "    Bar chart comparing correlations with SPY in different regimes.\n",
    "    \"\"\"\n",
    "    if 'Low VIX (<20)' not in corr_regimes or 'High VIX (>30)' not in corr_regimes:\n",
    "        return None\n",
    "    \n",
    "    low_corr = corr_regimes['Low VIX (<20)']['corr']\n",
    "    high_corr = corr_regimes['High VIX (>30)']['corr']\n",
    "    \n",
    "    countries = ['Germany', 'UK', 'France', 'Japan', 'China', 'Canada', 'Australia', 'Korea', 'Italy']\n",
    "    data = []\n",
    "    \n",
    "    for c in countries:\n",
    "        if c in low_corr.columns and c in high_corr.columns and 'SPY' in low_corr.columns:\n",
    "            data.append({\n",
    "                'Country': c,\n",
    "                'Low VIX': low_corr.loc[c, 'SPY'] if c != 'SPY' else 1.0,\n",
    "                'High VIX': high_corr.loc[c, 'SPY'] if c != 'SPY' else 1.0,\n",
    "            })\n",
    "    \n",
    "    if not data:\n",
    "        return None\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df['Change'] = df['High VIX'] - df['Low VIX']\n",
    "    df = df.sort_values('Change', ascending=False)\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        x=df['Country'], y=df['Low VIX'],\n",
    "        name='Low VIX (<20)', marker_color='#2ca02c'\n",
    "    ))\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=df['Country'], y=df['High VIX'],\n",
    "        name='High VIX (>30)', marker_color='#d62728'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text='<b>Correlation with SPY: Low vs High VIX Regimes</b><br>'\n",
    "                 '<sup>All correlations increase during market stress (diversification fails when needed most)</sup>',\n",
    "            x=0.5, font=dict(size=16)\n",
    "        ),\n",
    "        barmode='group',\n",
    "        yaxis_title='Correlation with SPY',\n",
    "        height=500, width=1000,\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "if corr_regimes:\n",
    "    fig_corr_change = create_correlation_change_chart(corr_regimes)\n",
    "    if fig_corr_change:\n",
    "        fig_corr_change.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üéØ SECTION C: Factor Decomposition\n",
    "\n",
    "Decomposing country returns into factor exposures: Market, Value, Momentum, Quality, Size, Low Vol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_factor_exposures(country_returns: pd.DataFrame,\n",
    "                                factor_returns: pd.DataFrame,\n",
    "                                window: int = 52) -> dict:\n",
    "    \"\"\"\n",
    "    Calculate factor exposures using OLS regression.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict: {country: {alpha, r_squared, betas, t_stats, rolling_betas}}\n",
    "    \"\"\"\n",
    "    if not STATSMODELS_AVAILABLE:\n",
    "        print(\"‚ö†Ô∏è statsmodels not available - skipping factor analysis\")\n",
    "        return {}\n",
    "    \n",
    "    factors = ['Market', 'Value', 'Momentum', 'Quality', 'Size', 'Low Vol']\n",
    "    available_factors = [f for f in factors if f in factor_returns.columns]\n",
    "    \n",
    "    if len(available_factors) < 2:\n",
    "        return {}\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for country in country_returns.columns:\n",
    "        if country == 'SPY':\n",
    "            continue\n",
    "        \n",
    "        common_idx = country_returns.index.intersection(factor_returns.index)\n",
    "        y = country_returns.loc[common_idx, country]\n",
    "        X = factor_returns.loc[common_idx, available_factors]\n",
    "        \n",
    "        mask = y.notna() & X.notna().all(axis=1)\n",
    "        y_clean = y[mask]\n",
    "        X_clean = X[mask]\n",
    "        \n",
    "        if len(y_clean) < 50:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            X_const = add_constant(X_clean)\n",
    "            model = OLS(y_clean, X_const).fit()\n",
    "            \n",
    "            results[country] = {\n",
    "                'alpha': model.params.get('const', 0),\n",
    "                'r_squared': model.rsquared,\n",
    "                'betas': {f: model.params.get(f, 0) for f in available_factors},\n",
    "                't_stats': {f: model.tvalues.get(f, 0) for f in available_factors},\n",
    "            }\n",
    "            \n",
    "            # Rolling betas for Market and Momentum\n",
    "            results[country]['rolling_betas'] = {}\n",
    "            for factor in ['Market', 'Momentum']:\n",
    "                if factor in available_factors:\n",
    "                    rolling_beta = []\n",
    "                    for i in range(window, len(y_clean)):\n",
    "                        y_w = y_clean.iloc[i-window:i]\n",
    "                        X_w = add_constant(X_clean.iloc[i-window:i])\n",
    "                        try:\n",
    "                            m = OLS(y_w, X_w).fit()\n",
    "                            rolling_beta.append({\n",
    "                                'date': y_clean.index[i],\n",
    "                                'beta': m.params.get(factor, np.nan)\n",
    "                            })\n",
    "                        except:\n",
    "                            pass\n",
    "                    \n",
    "                    if rolling_beta:\n",
    "                        results[country]['rolling_betas'][factor] = \\\n",
    "                            pd.DataFrame(rolling_beta).set_index('date')['beta']\n",
    "                        \n",
    "        except Exception as e:\n",
    "            pass\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Calculate factor exposures\n",
    "print(\"üéØ Calculating factor exposures...\")\n",
    "factor_exposures = calculate_factor_exposures(weekly_returns, factor_returns)\n",
    "\n",
    "print(f\"\\n‚úÖ Factor analysis completed for {len(factor_exposures)} countries\")\n",
    "\n",
    "# Display summary\n",
    "if factor_exposures:\n",
    "    print(\"\\nüìä Factor Exposure Summary:\")\n",
    "    for country in list(factor_exposures.keys())[:5]:\n",
    "        exp = factor_exposures[country]\n",
    "        print(f\"\\n   {country}:\")\n",
    "        print(f\"      R¬≤ = {exp['r_squared']:.1%}\")\n",
    "        print(f\"      Market Œ≤ = {exp['betas'].get('Market', 0):.2f}\")\n",
    "        print(f\"      Momentum Œ≤ = {exp['betas'].get('Momentum', 0):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factor Exposure Heatmap\n",
    "def create_factor_exposure_heatmap(factor_exposures: dict) -> go.Figure:\n",
    "    \"\"\"\n",
    "    Create heatmap of factor exposures across countries.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for country, exp in factor_exposures.items():\n",
    "        row = {'Country': country, 'Alpha': exp['alpha'], 'R¬≤': exp['r_squared']}\n",
    "        row.update(exp['betas'])\n",
    "        data.append(row)\n",
    "    \n",
    "    if not data:\n",
    "        return None\n",
    "    \n",
    "    df = pd.DataFrame(data).sort_values('R¬≤', ascending=False)\n",
    "    \n",
    "    factor_cols = [c for c in df.columns if c not in ['Country', 'Alpha', 'R¬≤']]\n",
    "    \n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=df[factor_cols].values,\n",
    "        x=factor_cols,\n",
    "        y=df['Country'],\n",
    "        colorscale='RdBu_r',\n",
    "        zmid=0 if 'Market' not in factor_cols else 1,\n",
    "        text=np.round(df[factor_cols].values, 2),\n",
    "        texttemplate='%{text}',\n",
    "        textfont={\"size\": 10},\n",
    "        colorbar=dict(title='Beta')\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text='<b>üéØ Factor Exposures by Country</b><br>'\n",
    "                 '<sup>Market, Value, Momentum, Quality, Size, Low Vol | Red=Positive, Blue=Negative</sup>',\n",
    "            x=0.5, font=dict(size=16)\n",
    "        ),\n",
    "        height=550, width=950,\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "if factor_exposures:\n",
    "    fig_factors = create_factor_exposure_heatmap(factor_exposures)\n",
    "    if fig_factors:\n",
    "        fig_factors.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üé≤ SECTION D: Monte Carlo Simulations\n",
    "\n",
    "Forward-looking scenarios using Geometric Brownian Motion, VaR, CVaR, and stress testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_monte_carlo(returns: pd.Series, n_sims: int = 10000, n_days: int = 252,\n",
    "                    initial_price: float = 100) -> dict:\n",
    "    \"\"\"\n",
    "    Run Monte Carlo simulation using Geometric Brownian Motion.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    returns : pd.Series\n",
    "        Daily returns in percentage\n",
    "    n_sims : int\n",
    "        Number of simulations\n",
    "    n_days : int\n",
    "        Number of trading days to simulate\n",
    "    initial_price : float\n",
    "        Starting price\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict containing price_paths, final_returns, stats, and params\n",
    "    \"\"\"\n",
    "    # Estimate parameters from historical data\n",
    "    daily_mean = returns.mean() / 100\n",
    "    daily_std = returns.std() / 100\n",
    "    \n",
    "    # Annualize\n",
    "    annual_return = daily_mean * 252\n",
    "    annual_vol = daily_std * np.sqrt(252)\n",
    "    \n",
    "    dt = 1 / 252\n",
    "    \n",
    "    # Generate random paths using GBM\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    random_matrix = np.random.standard_normal((n_days, n_sims))\n",
    "    \n",
    "    drift = (annual_return - 0.5 * annual_vol**2) * dt\n",
    "    diffusion = annual_vol * np.sqrt(dt) * random_matrix\n",
    "    \n",
    "    daily_returns_sim = drift + diffusion\n",
    "    \n",
    "    # Convert to price paths\n",
    "    price_paths = initial_price * np.exp(np.cumsum(daily_returns_sim, axis=0))\n",
    "    price_paths = np.vstack([np.full(n_sims, initial_price), price_paths])\n",
    "    \n",
    "    # Calculate final statistics\n",
    "    final_prices = price_paths[-1, :]\n",
    "    final_returns = (final_prices / initial_price - 1) * 100\n",
    "    \n",
    "    results = {\n",
    "        'price_paths': price_paths,\n",
    "        'final_returns': final_returns,\n",
    "        'stats': {\n",
    "            'mean': final_returns.mean(),\n",
    "            'median': np.median(final_returns),\n",
    "            'std': final_returns.std(),\n",
    "            'var_95': np.percentile(final_returns, 5),\n",
    "            'var_99': np.percentile(final_returns, 1),\n",
    "            'cvar_95': final_returns[final_returns <= np.percentile(final_returns, 5)].mean(),\n",
    "            'cvar_99': final_returns[final_returns <= np.percentile(final_returns, 1)].mean(),\n",
    "            'prob_positive': (final_returns > 0).mean() * 100,\n",
    "            'prob_10_gain': (final_returns > 10).mean() * 100,\n",
    "            'prob_10_loss': (final_returns < -10).mean() * 100,\n",
    "            'prob_20_loss': (final_returns < -20).mean() * 100,\n",
    "            'percentiles': {\n",
    "                '5th': np.percentile(final_returns, 5),\n",
    "                '25th': np.percentile(final_returns, 25),\n",
    "                '50th': np.percentile(final_returns, 50),\n",
    "                '75th': np.percentile(final_returns, 75),\n",
    "                '95th': np.percentile(final_returns, 95),\n",
    "            }\n",
    "        },\n",
    "        'params': {\n",
    "            'annual_return': annual_return,\n",
    "            'annual_vol': annual_vol\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def run_stress_scenarios(returns: pd.Series, initial_price: float = 100) -> dict:\n",
    "    \"\"\"\n",
    "    Run stress test scenarios.\n",
    "    \"\"\"\n",
    "    daily_mean = returns.mean() / 100\n",
    "    daily_std = returns.std() / 100\n",
    "    \n",
    "    annual_return = daily_mean * 252\n",
    "    annual_vol = daily_std * np.sqrt(252)\n",
    "    \n",
    "    scenarios = {\n",
    "        'Base Case': {'mu': annual_return, 'sigma': annual_vol},\n",
    "        'Bull Market': {'mu': annual_return + 0.10, 'sigma': annual_vol * 0.8},\n",
    "        'Bear Market': {'mu': annual_return - 0.15, 'sigma': annual_vol * 1.3},\n",
    "        'High Vol': {'mu': annual_return * 0.5, 'sigma': annual_vol * 2.0},\n",
    "        'Low Vol': {'mu': annual_return * 1.2, 'sigma': annual_vol * 0.6},\n",
    "        'Market Crash': {'mu': -0.35, 'sigma': annual_vol * 2.5},\n",
    "        'Recovery': {'mu': 0.30, 'sigma': annual_vol * 1.5},\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    n_sims = 1000\n",
    "    n_days = 252\n",
    "    dt = 1 / 252\n",
    "    \n",
    "    for name, params in scenarios.items():\n",
    "        np.random.seed(42)\n",
    "        mu, sigma = params['mu'], params['sigma']\n",
    "        \n",
    "        random_matrix = np.random.standard_normal((n_days, n_sims))\n",
    "        drift = (mu - 0.5 * sigma**2) * dt\n",
    "        diffusion = sigma * np.sqrt(dt) * random_matrix\n",
    "        \n",
    "        price_paths = initial_price * np.exp(np.cumsum(drift + diffusion, axis=0))\n",
    "        final_returns = (price_paths[-1, :] / initial_price - 1) * 100\n",
    "        \n",
    "        results[name] = {\n",
    "            'mean_return': final_returns.mean(),\n",
    "            'var_95': np.percentile(final_returns, 5),\n",
    "            'prob_positive': (final_returns > 0).mean() * 100,\n",
    "            'max_loss': final_returns.min(),\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Run Monte Carlo for key markets\n",
    "print(\"üé≤ Running Monte Carlo simulations (10,000 paths each)...\")\n",
    "\n",
    "mc_results = {}\n",
    "stress_results = {}\n",
    "\n",
    "for country in ['SPY', 'Germany', 'UK', 'Japan', 'China', 'France']:\n",
    "    if country in daily_returns.columns:\n",
    "        ret = daily_returns[country].dropna()\n",
    "        if len(ret) > 100:\n",
    "            print(f\"   ‚Ä¢ {country}...\", end=\" \")\n",
    "            mc_results[country] = run_monte_carlo(ret)\n",
    "            stress_results[country] = run_stress_scenarios(ret)\n",
    "            print(\"‚úì\")\n",
    "\n",
    "print(f\"\\n‚úÖ Monte Carlo completed for {len(mc_results)} markets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Monte Carlo Summary\n",
    "print(\"\\nüìä MONTE CARLO SIMULATION RESULTS (1-Year Forward)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "mc_summary = []\n",
    "for country, mc in mc_results.items():\n",
    "    s = mc['stats']\n",
    "    p = mc['params']\n",
    "    mc_summary.append({\n",
    "        'Country': country,\n",
    "        'Ann. Return': f\"{p['annual_return']:.1%}\",\n",
    "        'Ann. Vol': f\"{p['annual_vol']:.1%}\",\n",
    "        'Expected': f\"{s['mean']:.1f}%\",\n",
    "        'VaR 95%': f\"{s['var_95']:.1f}%\",\n",
    "        'CVaR 95%': f\"{s['cvar_95']:.1f}%\",\n",
    "        'P(+)': f\"{s['prob_positive']:.0f}%\",\n",
    "        'P(>10%)': f\"{s['prob_10_gain']:.0f}%\",\n",
    "        'P(<-20%)': f\"{s['prob_20_loss']:.0f}%\",\n",
    "    })\n",
    "\n",
    "display(pd.DataFrame(mc_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo Dashboard for SPY\n",
    "def create_monte_carlo_dashboard(mc_results: dict, country: str) -> go.Figure:\n",
    "    \"\"\"\n",
    "    Create comprehensive Monte Carlo visualization.\n",
    "    \"\"\"\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            f'{country}: Simulated Price Paths (200 of 10,000)',\n",
    "            'Distribution of 1-Year Returns',\n",
    "            'Return Percentiles',\n",
    "            'Risk Metrics Summary'\n",
    "        ),\n",
    "        specs=[[{'type': 'scatter'}, {'type': 'histogram'}],\n",
    "               [{'type': 'bar'}, {'type': 'table'}]]\n",
    "    )\n",
    "    \n",
    "    paths = mc_results['price_paths']\n",
    "    stats = mc_results['stats']\n",
    "    params = mc_results['params']\n",
    "    \n",
    "    # 1. Sample paths\n",
    "    n_show = min(200, paths.shape[1])\n",
    "    for i in range(n_show):\n",
    "        fig.add_trace(go.Scatter(\n",
    "            y=paths[:, i],\n",
    "            mode='lines',\n",
    "            line=dict(width=0.3, color='rgba(31, 119, 180, 0.15)'),\n",
    "            showlegend=False\n",
    "        ), row=1, col=1)\n",
    "    \n",
    "    # Percentile bands\n",
    "    p5 = np.percentile(paths, 5, axis=1)\n",
    "    p50 = np.percentile(paths, 50, axis=1)\n",
    "    p95 = np.percentile(paths, 95, axis=1)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(y=p50, mode='lines', name='Median',\n",
    "                             line=dict(color='red', width=2.5)), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(y=p5, mode='lines', name='5th %ile',\n",
    "                             line=dict(color='green', width=2, dash='dash')), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(y=p95, mode='lines', name='95th %ile',\n",
    "                             line=dict(color='orange', width=2, dash='dash')), row=1, col=1)\n",
    "    \n",
    "    # 2. Histogram\n",
    "    fig.add_trace(go.Histogram(\n",
    "        x=mc_results['final_returns'],\n",
    "        nbinsx=75,\n",
    "        marker_color='#1f77b4',\n",
    "        opacity=0.7,\n",
    "        showlegend=False\n",
    "    ), row=1, col=2)\n",
    "    \n",
    "    fig.add_vline(x=stats['var_95'], line_dash=\"dash\", line_color=\"red\", row=1, col=2)\n",
    "    fig.add_vline(x=stats['var_99'], line_dash=\"dash\", line_color=\"darkred\", row=1, col=2)\n",
    "    fig.add_vline(x=0, line_dash=\"solid\", line_color=\"black\", row=1, col=2)\n",
    "    \n",
    "    # 3. Percentiles bar\n",
    "    pctl = stats['percentiles']\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=list(pctl.keys()),\n",
    "        y=list(pctl.values()),\n",
    "        marker_color=['#d62728', '#ff7f0e', '#2ca02c', '#ff7f0e', '#d62728'],\n",
    "        text=[f'{v:.1f}%' for v in pctl.values()],\n",
    "        textposition='outside',\n",
    "        showlegend=False\n",
    "    ), row=2, col=1)\n",
    "    fig.add_hline(y=0, line_dash=\"solid\", line_color=\"black\", row=2, col=1)\n",
    "    \n",
    "    # 4. Table\n",
    "    metrics = [\n",
    "        ['Expected Return', f\"{stats['mean']:.1f}%\"],\n",
    "        ['Median Return', f\"{stats['median']:.1f}%\"],\n",
    "        ['Volatility', f\"{stats['std']:.1f}%\"],\n",
    "        ['VaR (95%)', f\"{stats['var_95']:.1f}%\"],\n",
    "        ['CVaR (95%)', f\"{stats['cvar_95']:.1f}%\"],\n",
    "        ['VaR (99%)', f\"{stats['var_99']:.1f}%\"],\n",
    "        ['P(Return > 0)', f\"{stats['prob_positive']:.0f}%\"],\n",
    "        ['P(Return > 10%)', f\"{stats['prob_10_gain']:.0f}%\"],\n",
    "        ['P(Return < -10%)', f\"{stats['prob_10_loss']:.0f}%\"],\n",
    "        ['P(Return < -20%)', f\"{stats['prob_20_loss']:.0f}%\"],\n",
    "    ]\n",
    "    \n",
    "    fig.add_trace(go.Table(\n",
    "        header=dict(\n",
    "            values=['<b>Metric</b>', '<b>Value</b>'],\n",
    "            fill_color='#1f77b4',\n",
    "            font=dict(color='white', size=11),\n",
    "            align='left'\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[[m[0] for m in metrics], [m[1] for m in metrics]],\n",
    "            fill_color='white',\n",
    "            align='left'\n",
    "        )\n",
    "    ), row=2, col=2)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=f'<b>üé≤ {country} Monte Carlo Simulation (1-Year Forward)</b><br>'\n",
    "                 f'<sup>Œº = {params[\"annual_return\"]:.1%}/yr | œÉ = {params[\"annual_vol\"]:.1%}/yr | 10,000 simulations</sup>',\n",
    "            x=0.5, font=dict(size=16)\n",
    "        ),\n",
    "        height=800, width=1200,\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(title_text='Trading Days', row=1, col=1)\n",
    "    fig.update_yaxes(title_text='Price', row=1, col=1)\n",
    "    fig.update_xaxes(title_text='1-Year Return (%)', row=1, col=2)\n",
    "    fig.update_yaxes(title_text='Return (%)', row=2, col=1)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "# Show SPY Monte Carlo\n",
    "if 'SPY' in mc_results:\n",
    "    fig_mc_spy = create_monte_carlo_dashboard(mc_results['SPY'], 'SPY')\n",
    "    fig_mc_spy.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Germany Monte Carlo\n",
    "if 'Germany' in mc_results:\n",
    "    fig_mc_ger = create_monte_carlo_dashboard(mc_results['Germany'], 'Germany')\n",
    "    fig_mc_ger.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stress Test Visualization\n",
    "def create_stress_test_chart(stress_results: dict, country: str) -> go.Figure:\n",
    "    \"\"\"\n",
    "    Visualize stress test scenarios.\n",
    "    \"\"\"\n",
    "    scenarios = list(stress_results.keys())\n",
    "    mean_returns = [stress_results[s]['mean_return'] for s in scenarios]\n",
    "    var_95 = [stress_results[s]['var_95'] for s in scenarios]\n",
    "    prob_pos = [stress_results[s]['prob_positive'] for s in scenarios]\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=3,\n",
    "        subplot_titles=('Expected Return', 'Value at Risk (95%)', 'P(Positive Return)')\n",
    "    )\n",
    "    \n",
    "    # Mean returns\n",
    "    colors_mean = ['#2ca02c' if r > 0 else '#d62728' for r in mean_returns]\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=scenarios, y=mean_returns,\n",
    "        marker_color=colors_mean,\n",
    "        text=[f'{r:.0f}%' for r in mean_returns],\n",
    "        textposition='outside',\n",
    "        showlegend=False\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    # VaR\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=scenarios, y=var_95,\n",
    "        marker_color='#d62728',\n",
    "        text=[f'{r:.0f}%' for r in var_95],\n",
    "        textposition='outside',\n",
    "        showlegend=False\n",
    "    ), row=1, col=2)\n",
    "    \n",
    "    # Prob positive\n",
    "    colors_prob = ['#2ca02c' if p > 50 else '#d62728' for p in prob_pos]\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=scenarios, y=prob_pos,\n",
    "        marker_color=colors_prob,\n",
    "        text=[f'{p:.0f}%' for p in prob_pos],\n",
    "        textposition='outside',\n",
    "        showlegend=False\n",
    "    ), row=1, col=3)\n",
    "    fig.add_hline(y=50, line_dash=\"dash\", line_color=\"gray\", row=1, col=3)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=f'<b>‚ö†Ô∏è {country} Stress Test Scenarios (1-Year)</b><br>'\n",
    "                 '<sup>Performance under different market conditions</sup>',\n",
    "            x=0.5, font=dict(size=16)\n",
    "        ),\n",
    "        height=450, width=1300,\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(tickangle=45)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "if 'SPY' in stress_results:\n",
    "    fig_stress = create_stress_test_chart(stress_results['SPY'], 'SPY')\n",
    "    fig_stress.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üìâ SECTION E: Value at Risk Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VaR Comparison Across Countries\n",
    "def create_var_comparison(returns: pd.DataFrame) -> go.Figure:\n",
    "    \"\"\"\n",
    "    Compare VaR across all countries.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for country in returns.columns:\n",
    "        if country == 'SPY':\n",
    "            continue\n",
    "        ret = returns[country].dropna()\n",
    "        if len(ret) > 50:\n",
    "            var_95 = np.percentile(ret, 5)\n",
    "            data.append({\n",
    "                'Country': country,\n",
    "                'Region': COUNTRY_TO_REGION.get(country, 'Unknown'),\n",
    "                'VaR 95%': var_95,\n",
    "                'CVaR 95%': ret[ret <= var_95].mean(),\n",
    "                'Max Loss': ret.min(),\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(data).sort_values('VaR 95%')\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        y=df['Country'], x=df['VaR 95%'],\n",
    "        name='VaR 95%', orientation='h',\n",
    "        marker_color='#ff7f0e'\n",
    "    ))\n",
    "    fig.add_trace(go.Bar(\n",
    "        y=df['Country'], x=df['CVaR 95%'],\n",
    "        name='CVaR 95%', orientation='h',\n",
    "        marker_color='#d62728'\n",
    "    ))\n",
    "    fig.add_trace(go.Bar(\n",
    "        y=df['Country'], x=df['Max Loss'],\n",
    "        name='Max Weekly Loss', orientation='h',\n",
    "        marker_color='#7f7f7f'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text='<b>üìâ Value at Risk Comparison (Weekly)</b><br>'\n",
    "                 '<sup>VaR (95%), CVaR (Expected Shortfall), Maximum Weekly Loss</sup>',\n",
    "            x=0.5, font=dict(size=16)\n",
    "        ),\n",
    "        barmode='group',\n",
    "        xaxis_title='Return (%)',\n",
    "        height=600, width=1000,\n",
    "        template='plotly_white',\n",
    "        legend=dict(orientation='h', y=1.02)\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "fig_var = create_var_comparison(weekly_returns)\n",
    "fig_var.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üíæ SECTION F: Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all results\n",
    "output_dir = './output_v4'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Statistics CSV\n",
    "stats_df.to_csv(f'{output_dir}/country_statistics.csv', index=False)\n",
    "print(f\"‚úÖ Saved: {output_dir}/country_statistics.csv\")\n",
    "\n",
    "# Monte Carlo summary\n",
    "mc_df = pd.DataFrame(mc_summary)\n",
    "mc_df.to_csv(f'{output_dir}/monte_carlo_summary.csv', index=False)\n",
    "print(f\"‚úÖ Saved: {output_dir}/monte_carlo_summary.csv\")\n",
    "\n",
    "# Weekly returns\n",
    "weekly_returns.to_csv(f'{output_dir}/weekly_returns.csv')\n",
    "print(f\"‚úÖ Saved: {output_dir}/weekly_returns.csv\")\n",
    "\n",
    "# Factor exposures\n",
    "if factor_exposures:\n",
    "    factor_data = []\n",
    "    for country, exp in factor_exposures.items():\n",
    "        row = {'Country': country, 'Alpha': exp['alpha'], 'R2': exp['r_squared']}\n",
    "        row.update(exp['betas'])\n",
    "        factor_data.append(row)\n",
    "    pd.DataFrame(factor_data).to_csv(f'{output_dir}/factor_exposures.csv', index=False)\n",
    "    print(f\"‚úÖ Saved: {output_dir}/factor_exposures.csv\")\n",
    "\n",
    "print(f\"\\nüìÅ All files saved to: {os.path.abspath(output_dir)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üéØ Summary\n",
    "\n",
    "This notebook provides institutional-grade analysis including:\n",
    "\n",
    "1. **Options-Implied Volatility** - VIX term structure, IV-RV spread, volatility risk premium\n",
    "2. **Correlation Regimes** - How correlations change between calm and crisis periods\n",
    "3. **Factor Decomposition** - Exposures to Market, Value, Momentum, Quality, Size, Low Vol\n",
    "4. **Monte Carlo Simulations** - 10,000 path simulations with VaR, CVaR, and stress testing\n",
    "5. **60+ Geopolitical Events** - Trump tariffs, Israel-Iran, Ukraine-Russia, semiconductors\n",
    "\n",
    "**Key Takeaways:**\n",
    "- Correlations increase during high volatility (diversification fails when needed most)\n",
    "- VIX typically trades above realized volatility (volatility risk premium)\n",
    "- Different countries have different factor exposures\n",
    "- Monte Carlo shows probability distributions for forward scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéâ ANALYSIS COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nüìä Analyzed {len(prices.columns)} international indices\")\n",
    "print(f\"üìÖ Date range: {prices.index.min().strftime('%Y-%m-%d')} to {prices.index.max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"üé≤ Monte Carlo simulations: {len(mc_results)} markets\")\n",
    "print(f\"üéØ Factor analysis: {len(factor_exposures)} countries\")\n",
    "print(f\"üì∞ Geopolitical events: {len(GEOPOLITICAL_EVENTS)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}